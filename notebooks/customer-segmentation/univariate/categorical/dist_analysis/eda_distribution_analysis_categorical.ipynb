{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115d65d6",
   "metadata": {},
   "source": [
    "I'll help you understand the comprehensive range of distribution analysis techniques for categorical columns. Let me first examine your current project structure and the specific notebook you're working with to provide context-aware insights.\n",
    "\n",
    "[5 tools called]\n",
    "\n",
    "Based on my analysis of your customer segmentation project, I can see you're working with the Mall Customers dataset which contains a **Gender** categorical variable. Let me provide you with a comprehensive overview of distribution analysis techniques for categorical columns, expanding significantly on your current framework.\n",
    "\n",
    "## **Complete Distribution Analysis Framework for Categorical Variables**\n",
    "\n",
    "### **1. Basic Distribution Characteristics**\n",
    "\n",
    "**Frequency Analysis:**\n",
    "- **Absolute frequencies** (`value_counts()`)\n",
    "- **Relative frequencies** (`value_counts(normalize=True)`)\n",
    "- **Cumulative frequencies** \n",
    "- **Percentile-based analysis**\n",
    "\n",
    "**Central Tendency:**\n",
    "- **Mode identification** (most frequent category)\n",
    "- **Modal frequency** and **modal percentage**\n",
    "- **Multimodal detection** (multiple modes)\n",
    "\n",
    "### **2. Balance & Imbalance Assessment** *(Your Current Focus)*\n",
    "\n",
    "**Class Imbalance Metrics:**\n",
    "- **Imbalance Ratio** (majority:minority ratio)\n",
    "- **Dominance Index** (proportion of most frequent class)\n",
    "- **Minority Representation** (smallest class proportion)\n",
    "- **Herfindahl-Hirschman Index** (concentration measure)\n",
    "\n",
    "**Balance Classification:**\n",
    "- **Balanced** (roughly equal proportions)\n",
    "- **Moderately Imbalanced** (2:1 to 4:1 ratio)\n",
    "- **Severely Imbalanced** (>10:1 ratio)\n",
    "\n",
    "### **3. Distribution Shape & Uniformity**\n",
    "\n",
    "**Uniformity Measures:**\n",
    "- **Chi-square goodness of fit** (test against uniform distribution)\n",
    "- **Evenness Index** (how evenly distributed categories are)\n",
    "- **Simpson's Diversity Index**\n",
    "- **Shannon Entropy** (information content)\n",
    "\n",
    "**Distribution Patterns:**\n",
    "- **Uniform distribution** (equal frequencies)\n",
    "- **Skewed distribution** (one category dominates)\n",
    "- **Bimodal/Multimodal** (multiple peaks)\n",
    "- **U-shaped** (extremes more frequent than middle)\n",
    "\n",
    "### **4. Advanced Pattern Recognition** *(Your Current Section)*\n",
    "\n",
    "**Temporal Patterns:**\n",
    "- **Seasonal analysis** (if time-stamped data)\n",
    "- **Trend analysis** (changes over time periods)\n",
    "- **Cyclical patterns** (recurring patterns)\n",
    "- **Day-of-week/Month effects**\n",
    "\n",
    "**Spatial/Geographic Patterns:**\n",
    "- **Regional distribution** (if location data available)\n",
    "- **Urban vs Rural patterns**\n",
    "- **Clustering by geography**\n",
    "\n",
    "**Demographic Patterns:**\n",
    "- **Age group distributions**\n",
    "- **Gender-based patterns**\n",
    "- **Socioeconomic patterns**\n",
    "\n",
    "### **5. Comparative Distribution Analysis**\n",
    "\n",
    "**Cross-Category Analysis:**\n",
    "- **Contingency tables** (`pd.crosstab()`)\n",
    "- **Conditional distributions** (distribution within subgroups)\n",
    "- **Marginal distributions**\n",
    "- **Joint probability distributions**\n",
    "\n",
    "**Benchmarking:**\n",
    "- **Expected vs Observed** distributions\n",
    "- **Industry standard comparisons**\n",
    "- **Historical baseline comparisons**\n",
    "- **Population vs Sample** distribution comparison\n",
    "\n",
    "### **6. Statistical Distribution Tests**\n",
    "\n",
    "**Goodness of Fit Tests:**\n",
    "- **Chi-square test** (against expected distribution)\n",
    "- **Kolmogorov-Smirnov test** (for ordinal categories)\n",
    "- **Anderson-Darling test**\n",
    "\n",
    "**Randomness Tests:**\n",
    "- **Runs test** (for sequential data)\n",
    "- **Serial correlation** (for time series categorical data)\n",
    "\n",
    "### **7. Information-Theoretic Analysis**\n",
    "\n",
    "**Entropy Measures:**\n",
    "- **Shannon Entropy** (information content)\n",
    "- **RÃ©nyi Entropy** (generalized entropy)\n",
    "- **Cross-entropy** (between distributions)\n",
    "- **Mutual Information** (with other variables)\n",
    "\n",
    "**Complexity Measures:**\n",
    "- **Effective number of categories**\n",
    "- **Participation ratio**\n",
    "- **Information diversity**\n",
    "\n",
    "### **8. Outlier & Anomaly Detection**\n",
    "\n",
    "**Frequency-Based Outliers:**\n",
    "- **Rare categories** (below threshold frequency)\n",
    "- **Singleton categories** (appearing only once)\n",
    "- **Unexpected categories** (not in expected set)\n",
    "\n",
    "**Pattern Anomalies:**\n",
    "- **Sudden frequency changes** (in temporal data)\n",
    "- **Geographic anomalies** (unusual regional patterns)\n",
    "- **Contextual anomalies** (unusual given other variables)\n",
    "\n",
    "### **9. Stability & Robustness Analysis**\n",
    "\n",
    "**Distribution Stability:**\n",
    "- **Temporal stability** (consistency over time)\n",
    "- **Sample stability** (bootstrap analysis)\n",
    "- **Subset stability** (consistency across data subsets)\n",
    "\n",
    "**Sensitivity Analysis:**\n",
    "- **Impact of missing data** imputation\n",
    "- **Robustness to outliers**\n",
    "- **Effect of sample size** on distribution\n",
    "\n",
    "### **10. Practical Implementation Metrics**\n",
    "\n",
    "**Business-Relevant Measures:**\n",
    "- **Market share analysis** (for business categories)\n",
    "- **Customer segment sizes**\n",
    "- **Risk category distributions**\n",
    "- **Performance tier distributions**\n",
    "\n",
    "**Quality Indicators:**\n",
    "- **Data completeness** (non-missing percentage)\n",
    "- **Category consistency** (standardization level)\n",
    "- **Label quality** (proper categorization)\n",
    "\n",
    "### **Example Implementation for Your Gender Variable:**\n",
    "\n",
    "```python\n",
    "def comprehensive_categorical_analysis(df, column):\n",
    "    \"\"\"Complete distribution analysis for categorical variables\"\"\"\n",
    "    \n",
    "    # Basic distribution\n",
    "    counts = df[column].value_counts()\n",
    "    proportions = df[column].value_counts(normalize=True)\n",
    "    \n",
    "    # Balance assessment\n",
    "    imbalance_ratio = counts.max() / counts.min()\n",
    "    dominance_index = proportions.max()\n",
    "    \n",
    "    # Uniformity measures\n",
    "    n_categories = len(counts)\n",
    "    expected_uniform = 1 / n_categories\n",
    "    chi2_stat = sum((proportions - expected_uniform)**2 / expected_uniform)\n",
    "    \n",
    "    # Shannon entropy\n",
    "    shannon_entropy = -sum(proportions * np.log2(proportions))\n",
    "    max_entropy = np.log2(n_categories)\n",
    "    normalized_entropy = shannon_entropy / max_entropy\n",
    "    \n",
    "    # HHI and evenness\n",
    "    hhi = sum(proportions**2)\n",
    "    evenness = (1 - hhi) / (1 - 1/n_categories) if n_categories > 1 else 0\n",
    "    \n",
    "    return {\n",
    "        'counts': counts,\n",
    "        'proportions': proportions,\n",
    "        'imbalance_ratio': imbalance_ratio,\n",
    "        'dominance_index': dominance_index,\n",
    "        'shannon_entropy': shannon_entropy,\n",
    "        'normalized_entropy': normalized_entropy,\n",
    "        'hhi': hhi,\n",
    "        'evenness': evenness,\n",
    "        'chi2_uniformity': chi2_stat\n",
    "    }\n",
    "```\n",
    "\n",
    "This comprehensive framework covers all major aspects of categorical distribution analysis, from basic frequency counts to advanced information-theoretic measures. Each technique provides different insights into your data's categorical structure and can inform different aspects of your analysis and modeling decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c157914",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a714a15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project configuration:\n",
      "SLUG = customer-segmentation\n",
      "DATA_DIR = /Users/ravisharma/workdir/eda_practice/data/customer-segmentation\n",
      "DATASET_KEY = vjchoudhary7/customer-segmentation-tutorial-in-python\n",
      "FIG_DIR = /Users/ravisharma/workdir/eda_practice/figures/customer-segmentation\n",
      "REP_DIR = /Users/ravisharma/workdir/eda_practice/reports/customer-segmentation\n",
      "NOTEBOOK_DIR = /Users/ravisharma/workdir/eda_practice/notebooks/customer-segmentation\n",
      "Vars not found in globals: []\n"
     ]
    }
   ],
   "source": [
    "%store -r\n",
    "\n",
    "print(\"Project configuration:\")\n",
    "print(f\"SLUG = {SLUG}\")\n",
    "print(f\"DATA_DIR = {DATA_DIR}\")\n",
    "print(f\"DATASET_KEY = {DATASET_KEY}\")\n",
    "print(f\"FIG_DIR = {FIG_DIR}\")\n",
    "print(f\"REP_DIR = {REP_DIR}\")\n",
    "print(f\"NOTEBOOK_DIR = {NOTEBOOK_DIR}\")\n",
    "\n",
    "missing_vars = [var for var in ['SLUG', 'DATA_DIR', 'FIG_DIR', 'REP_DIR', 'NOTEBOOK_DIR', 'DATASET_KEY'] if var not in globals()]\n",
    "print(f\"Vars not found in globals: {missing_vars}\")\n",
    "\n",
    "# Set default values if variables are not found in store or are empty\n",
    "if not SLUG:  # Check if empty string\n",
    "    print(f\"{SLUG=} is empty, initializing everything explicitly\")\n",
    "    SLUG = 'customer-segmentation'\n",
    "    DATASET_KEY = 'vjchoudhary7/customer-segmentation-tutorial-in-python'\n",
    "    GIT_ROOT = Path.cwd().parent.parent\n",
    "    DATA_DIR = GIT_ROOT / 'data' / SLUG\n",
    "    FIG_DIR = GIT_ROOT / 'figures' / SLUG\n",
    "    REP_DIR = GIT_ROOT / 'reports' / SLUG\n",
    "    NOTEBOOK_DIR = GIT_ROOT / 'notebooks' / SLUG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e76f555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb3967f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV /Users/ravisharma/workdir/eda_practice/data/customer-segmentation/Mall_Customers.csv loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual Income (k$)</th>\n",
       "      <th>Spending Score (1-100)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Gender  Age  Annual Income (k$)  Spending Score (1-100)\n",
       "0           1    Male   19                  15                      39\n",
       "1           2    Male   21                  15                      81\n",
       "2           3  Female   20                  16                       6\n",
       "3           4  Female   23                  16                      77\n",
       "4           5  Female   31                  17                      40"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Downloading data\n",
    "\n",
    "base_df = pd.DataFrame()\n",
    "\n",
    "CSV_PATH = Path(DATA_DIR) / \"Mall_Customers.csv\"\n",
    "if not CSV_PATH.exists:\n",
    "    print(f\"CSV {CSV_PATH} does not exist. base_df will remain empty.\")\n",
    "else:\n",
    "    base_df = pd.read_csv(CSV_PATH)\n",
    "    print(f\"CSV {CSV_PATH} loaded successfully.\")\n",
    "\n",
    "base_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7bafd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual Income (k$)</th>\n",
       "      <th>Spending Score (1-100)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>100.500000</td>\n",
       "      <td>38.850000</td>\n",
       "      <td>60.560000</td>\n",
       "      <td>50.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>57.879185</td>\n",
       "      <td>13.969007</td>\n",
       "      <td>26.264721</td>\n",
       "      <td>25.823522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50.750000</td>\n",
       "      <td>28.750000</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>34.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>100.500000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>150.250000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CustomerID         Age  Annual Income (k$)  Spending Score (1-100)\n",
       "count  200.000000  200.000000          200.000000              200.000000\n",
       "mean   100.500000   38.850000           60.560000               50.200000\n",
       "std     57.879185   13.969007           26.264721               25.823522\n",
       "min      1.000000   18.000000           15.000000                1.000000\n",
       "25%     50.750000   28.750000           41.500000               34.750000\n",
       "50%    100.500000   36.000000           61.500000               50.000000\n",
       "75%    150.250000   49.000000           78.000000               73.000000\n",
       "max    200.000000   70.000000          137.000000               99.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eab24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical_features=['CustomerID', 'Age', 'Annual Income (k$)', 'Spending Score (1-100)']\n",
      "categorical_features=['Gender']\n",
      "datetime_features=[]\n",
      "id_column='CustomerID'\n",
      "Dropping id columns...\n",
      "numerical_features=['Age', 'Annual Income (k$)', 'Spending Score (1-100)']\n"
     ]
    }
   ],
   "source": [
    "base_df.dtypes\n",
    "numerical_features = base_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = base_df.select_dtypes(include=['object']).columns.tolist()\n",
    "datetime_features = base_df.select_dtypes(include=['datetime64']).columns.tolist()\n",
    "id_column = 'CustomerID'\n",
    "print(f\"{numerical_features=}\")\n",
    "print(f\"{categorical_features=}\")\n",
    "print(f\"{datetime_features=}\")\n",
    "print(f\"{id_column=}\")\n",
    "print(\"Dropping id columns...\")\n",
    "numerical_features.remove(id_column)\n",
    "print(f\"{numerical_features=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4b6f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing_data=CustomerID                0\n",
      "Gender                    0\n",
      "Age                       0\n",
      "Annual Income (k$)        0\n",
      "Spending Score (1-100)    0\n",
      "dtype: int64\n",
      "missing_data_pct=CustomerID                0.0\n",
      "Gender                    0.0\n",
      "Age                       0.0\n",
      "Annual Income (k$)        0.0\n",
      "Spending Score (1-100)    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "missing_data = base_df.isnull().sum() # a dataframe\n",
    "missing_data_pct = missing_data / len(base_df) * 100 # a dataframe with operation done column wise\n",
    "print(f\"{missing_data=}\")\n",
    "print(f\"{missing_data_pct=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea15f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967e65e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_results['dataset'] = {\n",
    "    \"missing_data\": missing_data.to_dict(),\n",
    "    \"missing_data_pct\": missing_data_pct.to_dict(),\n",
    "    \"numerical_features\": numerical_features,\n",
    "    \"categorical_features\": categorical_features,\n",
    "    \"datetime_features\": datetime_features,\n",
    "    \"shape\": base_df.shape\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45a72e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gender']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8544019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created categorical variables:\n",
      "Age Groups: Age_Group\n",
      "Adult (25-34)          54\n",
      "Middle-aged (35-49)    66\n",
      "Senior (50+)           45\n",
      "Young (18-24)          35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Income Groups: Income_Group\n",
      "High (> $70k)       76\n",
      "Low (< $40k)        46\n",
      "Medium ($40-70k)    78\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Spending Groups: Spending_Group\n",
      "High Spender (> 65)       59\n",
      "Low Spender (< 35)        50\n",
      "Medium Spender (35-65)    91\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## 1. Basic Cross-Tabulation with Numerical Variables\n",
    "\n",
    "# First, let's create categorical versions of numerical variables for cross-tabulation\n",
    "def create_age_groups(age):\n",
    "    \"\"\"Create age groups for cross-tabulation\"\"\"\n",
    "    if age < 25:\n",
    "        return \"Young (18-24)\"\n",
    "    elif age < 35:\n",
    "        return \"Adult (25-34)\" \n",
    "    elif age < 50:\n",
    "        return \"Middle-aged (35-49)\"\n",
    "    else:\n",
    "        return \"Senior (50+)\"\n",
    "\n",
    "def create_income_groups(income):\n",
    "    \"\"\"Create income groups for cross-tabulation\"\"\"\n",
    "    if income < 40:\n",
    "        return \"Low (< $40k)\"\n",
    "    elif income < 70:\n",
    "        return \"Medium ($40-70k)\"\n",
    "    else:\n",
    "        return \"High (> $70k)\"\n",
    "\n",
    "def create_spending_groups(spending):\n",
    "    \"\"\"Create spending score groups\"\"\"\n",
    "    if spending < 35:\n",
    "        return \"Low Spender (< 35)\"\n",
    "    elif spending < 65:\n",
    "        return \"Medium Spender (35-65)\"\n",
    "    else:\n",
    "        return \"High Spender (> 65)\"\n",
    "\n",
    "# Create categorical versions\n",
    "base_df['Age_Group'] = base_df['Age'].apply(create_age_groups)\n",
    "base_df['Income_Group'] = base_df['Annual Income (k$)'].apply(create_income_groups)\n",
    "base_df['Spending_Group'] = base_df['Spending Score (1-100)'].apply(create_spending_groups)\n",
    "\n",
    "print(\"Created categorical variables:\")\n",
    "print(\"Age Groups:\", base_df['Age_Group'].value_counts().sort_index())\n",
    "print(\"\\nIncome Groups:\", base_df['Income_Group'].value_counts().sort_index())\n",
    "print(\"\\nSpending Groups:\", base_df['Spending_Group'].value_counts().sort_index())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
