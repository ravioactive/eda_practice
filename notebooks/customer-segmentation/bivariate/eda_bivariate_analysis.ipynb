{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87ae431d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project configuration:\n",
      "SLUG = customer-segmentation\n",
      "DATA_DIR = /Users/ravisharma/workdir/eda_practice/data/customer-segmentation\n",
      "DATASET_KEY = vjchoudhary7/customer-segmentation-tutorial-in-python\n",
      "FIG_DIR = /Users/ravisharma/workdir/eda_practice/figures/customer-segmentation\n",
      "REP_DIR = /Users/ravisharma/workdir/eda_practice/reports/customer-segmentation\n",
      "NOTEBOOK_DIR = /Users/ravisharma/workdir/eda_practice/notebooks/customer-segmentation\n",
      "Vars not found in globals: []\n"
     ]
    }
   ],
   "source": [
    "%store -r\n",
    "\n",
    "print(\"Project configuration:\")\n",
    "print(f\"SLUG = {SLUG}\")\n",
    "print(f\"DATA_DIR = {DATA_DIR}\")\n",
    "print(f\"DATASET_KEY = {DATASET_KEY}\")\n",
    "print(f\"FIG_DIR = {FIG_DIR}\")\n",
    "print(f\"REP_DIR = {REP_DIR}\")\n",
    "print(f\"NOTEBOOK_DIR = {NOTEBOOK_DIR}\")\n",
    "\n",
    "missing_vars = [var for var in ['SLUG', 'DATA_DIR', 'FIG_DIR', 'REP_DIR', 'NOTEBOOK_DIR', 'DATASET_KEY'] if var not in globals()]\n",
    "print(f\"Vars not found in globals: {missing_vars}\")\n",
    "\n",
    "# Set default values if variables are not found in store or are empty\n",
    "if not SLUG:  # Check if empty string\n",
    "    print(f\"{SLUG=} is empty, initializing everything explicitly\")\n",
    "    SLUG = 'customer-segmentation'\n",
    "    DATASET_KEY = 'vjchoudhary7/customer-segmentation-tutorial-in-python'\n",
    "    GIT_ROOT = Path.cwd().parent.parent\n",
    "    DATA_DIR = GIT_ROOT / 'data' / SLUG\n",
    "    FIG_DIR = GIT_ROOT / 'figures' / SLUG\n",
    "    REP_DIR = GIT_ROOT / 'reports' / SLUG\n",
    "    NOTEBOOK_DIR = GIT_ROOT / 'notebooks' / SLUG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28c0e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "889bb5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV /Users/ravisharma/workdir/eda_practice/data/customer-segmentation/Mall_Customers.csv loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual Income (k$)</th>\n",
       "      <th>Spending Score (1-100)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Gender  Age  Annual Income (k$)  Spending Score (1-100)\n",
       "0           1    Male   19                  15                      39\n",
       "1           2    Male   21                  15                      81\n",
       "2           3  Female   20                  16                       6\n",
       "3           4  Female   23                  16                      77\n",
       "4           5  Female   31                  17                      40"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading data\n",
    "\n",
    "base_df = pd.DataFrame()\n",
    "\n",
    "CSV_PATH = Path(DATA_DIR) / \"Mall_Customers.csv\"\n",
    "if not CSV_PATH.exists:\n",
    "    print(f\"CSV {CSV_PATH} does not exist. base_df will remain empty.\")\n",
    "else:\n",
    "    base_df = pd.read_csv(CSV_PATH)\n",
    "    print(f\"CSV {CSV_PATH} loaded successfully.\")\n",
    "\n",
    "base_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8bf925",
   "metadata": {},
   "source": [
    "## ✅ **Plan Overview**\n",
    "\n",
    "The plan covers **10 major categories** of bivariate analysis techniques, each with detailed explanations of:\n",
    "- **What** each technique does\n",
    "- **When** to use it\n",
    "- **Why** it's important\n",
    "- **Relevance** to your specific dataset (marked with ✅, ⚠️, or ❌)\n",
    "\n",
    "## 🎯 **Key Features**\n",
    "\n",
    "1. **Comprehensive Coverage**: Includes techniques even if not directly applicable to your dataset (as requested)\n",
    "2. **Relevance Indicators**: \n",
    "   - ✅ Highly relevant/applicable\n",
    "   - ⚠️ Limited relevance or optional\n",
    "   - ❌ Not applicable but included for reference\n",
    "\n",
    "3. **Prioritized Approach**: Organized by importance for your customer segmentation problem\n",
    "\n",
    "## 📊 **Most Relevant Techniques for Your Dataset**\n",
    "\n",
    "**High Priority:**\n",
    "- Correlation analysis between Age, Income, and Spending Score\n",
    "- Scatter plots to identify customer clusters\n",
    "- Gender-based comparisons using t-tests and box plots\n",
    "- Joint distribution analysis\n",
    "- Clustering tendency validation\n",
    "\n",
    "**Medium Priority:**\n",
    "- Regression modeling\n",
    "- Outlier detection\n",
    "- Effect size calculations\n",
    "- Assumption testing\n",
    "\n",
    "## 🔍 **Included for Learning/Reference**\n",
    "\n",
    "Even though not applicable to your current dataset, I included:\n",
    "- **Time series analysis** (no temporal data)\n",
    "- **Categorical vs categorical analysis** (only one categorical variable)\n",
    "- **Advanced techniques** like mutual information\n",
    "- **Power analysis** methods\n",
    "\n",
    "This plan will serve as an excellent reference for future EDA projects and gives you a comprehensive roadmap for analyzing the customer segmentation dataset. You can now systematically work through the high-priority techniques first, then explore the medium-priority ones as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f805f5",
   "metadata": {},
   "source": [
    "# Comprehensive Bivariate Analysis Plan\n",
    "\n",
    "## Dataset Overview\n",
    "**Problem**: Customer Segmentation for Mall Customers\n",
    "- **Variables**: CustomerID, Gender, Age, Annual Income (k$), Spending Score (1-100)\n",
    "- **Data Types**: \n",
    "  - Categorical: Gender\n",
    "  - Numerical: Age, Annual Income, Spending Score\n",
    "  - Identifier: CustomerID (excluded from analysis)\n",
    "\n",
    "## Bivariate Analysis Framework\n",
    "\n",
    "### 1. Numerical vs Numerical Analysis\n",
    "\n",
    "#### 1.1 Correlation Analysis ✅ *Highly Relevant*\n",
    "- **Pearson Correlation Coefficient**: Linear relationships between continuous variables\n",
    "  - Age vs Annual Income\n",
    "  - Age vs Spending Score  \n",
    "  - Annual Income vs Spending Score\n",
    "- **Spearman Rank Correlation**: Monotonic relationships (non-linear)\n",
    "- **Kendall's Tau**: Alternative rank correlation for small samples\n",
    "- **When to use**: Always start with correlation for numerical pairs\n",
    "- **Interpretation**: r > 0.7 (strong), 0.3-0.7 (moderate), < 0.3 (weak)\n",
    "\n",
    "#### 1.2 Scatter Plot Analysis ✅ *Highly Relevant*\n",
    "- **Basic scatter plots** with trend lines\n",
    "- **Bubble plots** (3rd variable as size/color)\n",
    "- **Marginal plots** (histograms on axes)\n",
    "- **When to use**: Visualize relationships, identify outliers, non-linear patterns\n",
    "- **Look for**: Clusters, outliers, heteroscedasticity, non-linear patterns\n",
    "\n",
    "#### 1.3 Regression Analysis ✅ *Relevant*\n",
    "- **Simple Linear Regression**: Model relationships\n",
    "- **Polynomial Regression**: Capture non-linear relationships\n",
    "- **Residual Analysis**: Check assumptions\n",
    "- **When to use**: When one variable predicts another\n",
    "- **Metrics**: R², RMSE, residual patterns\n",
    "\n",
    "#### 1.4 Joint Distribution Analysis ✅ *Relevant*\n",
    "- **2D Histograms/Heatmaps**: Density of point clusters\n",
    "- **Contour plots**: Probability density contours\n",
    "- **Hexbin plots**: For large datasets\n",
    "- **When to use**: Understand joint probability distributions\n",
    "\n",
    "### 2. Categorical vs Numerical Analysis\n",
    "\n",
    "#### 2.1 Group Comparison Tests ✅ *Highly Relevant*\n",
    "- **Independent t-test**: Compare means between two groups (Gender vs Income/Spending/Age)\n",
    "- **Welch's t-test**: When variances are unequal\n",
    "- **Mann-Whitney U test**: Non-parametric alternative\n",
    "- **When to use**: Compare numerical variable across categorical groups\n",
    "- **Assumptions**: Normality, equal variances (for t-test)\n",
    "\n",
    "#### 2.2 Multiple Group Comparisons ⚠️ *Limited Relevance*\n",
    "- **One-way ANOVA**: Compare means across multiple groups\n",
    "- **Kruskal-Wallis test**: Non-parametric ANOVA\n",
    "- **Post-hoc tests**: Tukey HSD, Bonferroni\n",
    "- **When to use**: When categorical variable has >2 levels\n",
    "- **Note**: Limited relevance as Gender only has 2 levels\n",
    "\n",
    "#### 2.3 Visual Comparisons ✅ *Highly Relevant*\n",
    "- **Box plots**: Distribution comparison by groups\n",
    "- **Violin plots**: Density + box plot information\n",
    "- **Strip plots**: Individual data points\n",
    "- **Swarm plots**: Non-overlapping points\n",
    "- **When to use**: Visualize distribution differences across groups\n",
    "\n",
    "#### 2.4 Effect Size Measures ✅ *Relevant*\n",
    "- **Cohen's d**: Standardized mean difference\n",
    "- **Eta-squared (η²)**: Proportion of variance explained\n",
    "- **When to use**: Quantify practical significance beyond statistical significance\n",
    "\n",
    "### 3. Categorical vs Categorical Analysis\n",
    "\n",
    "#### 3.1 Contingency Table Analysis ❌ *Not Applicable*\n",
    "- **Cross-tabulation**: Frequency tables\n",
    "- **Chi-square test of independence**: Test association\n",
    "- **Fisher's exact test**: Small sample alternative\n",
    "- **When to use**: Two categorical variables\n",
    "- **Note**: Only one categorical variable (Gender) in dataset\n",
    "\n",
    "#### 3.2 Association Measures ❌ *Not Applicable*\n",
    "- **Cramér's V**: Strength of association\n",
    "- **Phi coefficient**: For 2x2 tables\n",
    "- **Lambda**: Proportional reduction in error\n",
    "- **When to use**: Measure strength of categorical associations\n",
    "- **Note**: Need multiple categorical variables\n",
    "\n",
    "### 4. Time Series Analysis ❌ *Not Applicable*\n",
    "- **Autocorrelation Function (ACF)**: Serial correlation\n",
    "- **Cross-correlation**: Relationship between time series\n",
    "- **Lag plots**: Temporal relationships\n",
    "- **Seasonal decomposition**: Trend, seasonal, residual components\n",
    "- **When to use**: Time-indexed data\n",
    "- **Note**: No temporal variables in dataset\n",
    "\n",
    "### 5. Advanced Bivariate Techniques\n",
    "\n",
    "#### 5.1 Non-parametric Methods ✅ *Relevant*\n",
    "- **Kernel Density Estimation**: Smooth density estimates\n",
    "- **Quantile-Quantile (Q-Q) plots**: Compare distributions\n",
    "- **Empirical Cumulative Distribution**: Distribution comparison\n",
    "- **When to use**: Non-normal data, distribution-free analysis\n",
    "\n",
    "#### 5.2 Robust Statistics ✅ *Relevant*\n",
    "- **Robust correlation**: Spearman, Kendall\n",
    "- **Median-based tests**: Mood's median test\n",
    "- **Trimmed means**: Reduce outlier influence\n",
    "- **When to use**: Presence of outliers, non-normal data\n",
    "\n",
    "#### 5.3 Information Theory Measures ⚠️ *Advanced/Optional*\n",
    "- **Mutual Information**: Non-linear dependencies\n",
    "- **Normalized Mutual Information**: Scaled version\n",
    "- **When to use**: Capture complex, non-linear relationships\n",
    "- **Note**: More advanced, may be overkill for this dataset\n",
    "\n",
    "### 6. Assumption Testing\n",
    "\n",
    "#### 6.1 Normality Tests ✅ *Important*\n",
    "- **Shapiro-Wilk test**: Small samples (n<50)\n",
    "- **Kolmogorov-Smirnov test**: Larger samples\n",
    "- **Anderson-Darling test**: More sensitive to tails\n",
    "- **Visual**: Q-Q plots, histograms\n",
    "- **When to use**: Before parametric tests\n",
    "\n",
    "#### 6.2 Homogeneity of Variance ✅ *Important*\n",
    "- **Levene's test**: Equal variances across groups\n",
    "- **Bartlett's test**: Assumes normality\n",
    "- **Brown-Forsythe test**: Robust alternative\n",
    "- **When to use**: Before ANOVA, t-tests\n",
    "\n",
    "#### 6.3 Independence Tests ✅ *Important*\n",
    "- **Durbin-Watson test**: Serial correlation\n",
    "- **Runs test**: Randomness\n",
    "- **When to use**: Verify independence assumption\n",
    "\n",
    "### 7. Outlier Detection in Bivariate Context\n",
    "\n",
    "#### 7.1 Bivariate Outlier Methods ✅ *Relevant*\n",
    "- **Mahalanobis Distance**: Multivariate outliers\n",
    "- **Cook's Distance**: Influential points in regression\n",
    "- **Leverage plots**: High-leverage points\n",
    "- **When to use**: Identify points affecting bivariate relationships\n",
    "\n",
    "### 8. Clustering Tendency Analysis\n",
    "\n",
    "#### 8.1 Cluster Validation ✅ *Highly Relevant*\n",
    "- **Hopkins statistic**: Clustering tendency\n",
    "- **Gap statistic**: Optimal cluster number\n",
    "- **Silhouette analysis**: Cluster quality\n",
    "- **When to use**: Before customer segmentation\n",
    "- **Note**: Directly relevant to customer segmentation problem\n",
    "\n",
    "### 9. Specialized Visualizations\n",
    "\n",
    "#### 9.1 Advanced Plots ✅ *Relevant*\n",
    "- **Pair plots**: All variable combinations\n",
    "- **Correlation heatmaps**: Matrix visualization\n",
    "- **Andrews curves**: Multivariate visualization\n",
    "- **Parallel coordinates**: High-dimensional relationships\n",
    "- **When to use**: Comprehensive relationship overview\n",
    "\n",
    "### 10. Statistical Power and Sample Size\n",
    "\n",
    "#### 10.1 Power Analysis ⚠️ *Optional*\n",
    "- **Post-hoc power**: Achieved power\n",
    "- **Effect size estimation**: Practical significance\n",
    "- **When to use**: Interpret non-significant results\n",
    "- **Note**: With n=200, likely adequate power for most tests\n",
    "\n",
    "## Analysis Priority for Customer Segmentation\n",
    "\n",
    "### High Priority ✅\n",
    "1. Correlation analysis (all numerical pairs)\n",
    "2. Scatter plots with clustering overlay\n",
    "3. Gender-based group comparisons\n",
    "4. Box plots by gender\n",
    "5. Joint distribution analysis\n",
    "6. Clustering tendency tests\n",
    "\n",
    "### Medium Priority ⚠️\n",
    "1. Regression analysis\n",
    "2. Robust correlation methods\n",
    "3. Outlier detection\n",
    "4. Effect size calculations\n",
    "5. Assumption testing\n",
    "\n",
    "### Low Priority/Reference ❌\n",
    "1. Time series methods\n",
    "2. Multiple categorical analysis\n",
    "3. Advanced information theory\n",
    "4. Power analysis\n",
    "\n",
    "## Expected Insights\n",
    "- **Income vs Spending**: Potential customer segments\n",
    "- **Age patterns**: Life-stage based behavior\n",
    "- **Gender differences**: Shopping behavior variations\n",
    "- **Clustering structure**: Natural customer groups for segmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a7f2f1",
   "metadata": {},
   "source": [
    "# OVERVIEW OF MISSING/INAPPLICABLE TECHNIQUES \n",
    "\n",
    "## ✅ **Comprehensive Coverage**\n",
    "\n",
    "### **1. Categorical vs Categorical Analysis**\n",
    "- **Cross-tabulation methods** with formulas and Python implementations\n",
    "- **Chi-square tests** including Fisher's exact and McNemar's tests\n",
    "- **Association measures** like Cramér's V, Phi coefficient, Lambda\n",
    "- **Ordinal analysis** with Gamma, Kendall's Tau variants, Somers' D\n",
    "\n",
    "### **2. Time Series Bivariate Analysis**\n",
    "- **Cross-correlation functions** with lag analysis\n",
    "- **Cointegration testing** (Engle-Granger, Johansen)\n",
    "- **Granger causality** and VAR models\n",
    "- **Spectral analysis** and wavelet methods\n",
    "\n",
    "### **3. Advanced Multivariate Techniques**\n",
    "- **Information theory measures** (Mutual Information, Transfer Entropy)\n",
    "- **Distance-based methods** (Distance correlation, MIC)\n",
    "- **Copula analysis** for dependence modeling\n",
    "\n",
    "### **4. Robust and Non-parametric Methods**\n",
    "- **Robust correlations** (Winsorized, Biweight, Percentage Bend)\n",
    "- **Detailed rank methods** (Spearman, Kendall variants)\n",
    "- **Distribution-free tests** (K-S, Anderson-Darling, Energy statistics)\n",
    "\n",
    "### **5. Specialized Domain Applications**\n",
    "- **Survival analysis** (Log-rank test, Cox regression)\n",
    "- **Spatial analysis** (Moran's I, Cross-variogram)\n",
    "- **Network analysis** methods\n",
    "\n",
    "### **6. Power Analysis and Sample Size**\n",
    "- **Effect size calculations** with Cohen's guidelines\n",
    "- **Sample size formulas** for different test types\n",
    "- **Multiple comparison corrections** (Bonferroni, FDR)\n",
    "\n",
    "## 🎯 **Key Features**\n",
    "\n",
    "- **Formulas included** for mathematical understanding\n",
    "- **Python implementations** specified where available\n",
    "- **When to use** guidance for each technique\n",
    "- **Assumptions and limitations** clearly stated\n",
    "- **Interpretation guidelines** provided\n",
    "\n",
    "This reference guide will serve you well when working on different types of datasets in the future - whether you encounter time series data, multiple categorical variables, or need specialized domain-specific analyses. You now have both a practical plan for your current customer segmentation project and a comprehensive reference for future EDA work!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d947ebb",
   "metadata": {},
   "source": [
    "# Detailed Reference Guide for Less Applicable Techniques\n",
    "\n",
    "*This section provides comprehensive details for bivariate analysis techniques that are not directly applicable to the current customer segmentation dataset but are important for other types of data analysis projects.*\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Categorical vs Categorical Analysis (Detailed Reference)\n",
    "\n",
    "### 1.1 Contingency Table Analysis\n",
    "**When applicable**: Two or more categorical variables\n",
    "\n",
    "#### Cross-tabulation (Crosstabs)\n",
    "- **Purpose**: Display frequency distribution of variables\n",
    "- **Output**: 2x2, 2xN, or NxM frequency tables\n",
    "- **Calculations**:\n",
    "  - Observed frequencies\n",
    "  - Expected frequencies: `(row_total × column_total) / grand_total`\n",
    "  - Row percentages, column percentages, total percentages\n",
    "- **Python**: `pd.crosstab()`, `pd.pivot_table()`\n",
    "\n",
    "#### Chi-Square Test of Independence\n",
    "- **Null Hypothesis**: Variables are independent\n",
    "- **Test Statistic**: `χ² = Σ[(Observed - Expected)² / Expected]`\n",
    "- **Degrees of Freedom**: `(rows-1) × (columns-1)`\n",
    "- **Assumptions**:\n",
    "  - Expected frequency ≥ 5 in at least 80% of cells\n",
    "  - No expected frequency < 1\n",
    "- **Python**: `scipy.stats.chi2_contingency()`\n",
    "- **Interpretation**: p < 0.05 suggests association exists\n",
    "\n",
    "#### Fisher's Exact Test\n",
    "- **When to use**: Small sample sizes, 2x2 tables\n",
    "- **Advantage**: Exact p-values, no minimum expected frequency requirement\n",
    "- **Limitation**: Computationally intensive for large tables\n",
    "- **Python**: `scipy.stats.fisher_exact()`\n",
    "\n",
    "#### McNemar's Test\n",
    "- **Purpose**: Paired categorical data (before/after comparisons)\n",
    "- **Structure**: 2x2 table with matched pairs\n",
    "- **Test Statistic**: `χ² = (b-c)² / (b+c)` where b,c are off-diagonal cells\n",
    "- **Python**: `statsmodels.stats.contingency_tables.mcnemar()`\n",
    "\n",
    "### 1.2 Association Measures\n",
    "\n",
    "#### Cramér's V\n",
    "- **Formula**: `V = √(χ² / (n × min(k-1, r-1)))`\n",
    "- **Range**: 0 (no association) to 1 (perfect association)\n",
    "- **Advantage**: Standardized, comparable across different table sizes\n",
    "- **Interpretation**: 0.1 (small), 0.3 (medium), 0.5 (large)\n",
    "\n",
    "#### Phi Coefficient (φ)\n",
    "- **For**: 2x2 tables only\n",
    "- **Formula**: `φ = √(χ² / n)`\n",
    "- **Range**: 0 to 1\n",
    "- **Relationship**: φ = Cramér's V for 2x2 tables\n",
    "\n",
    "#### Lambda (λ)\n",
    "- **Concept**: Proportional reduction in error\n",
    "- **Formula**: `λ = (E₁ - E₂) / E₁`\n",
    "- **Range**: 0 (no improvement) to 1 (perfect prediction)\n",
    "- **Types**: Symmetric lambda, asymmetric lambda\n",
    "\n",
    "#### Goodman and Kruskal's Tau\n",
    "- **Purpose**: Measure predictive association\n",
    "- **Advantage**: Accounts for ordinal nature of variables\n",
    "- **Range**: 0 to 1\n",
    "\n",
    "#### Uncertainty Coefficient (Theil's U)\n",
    "- **Based on**: Information theory\n",
    "- **Formula**: Uses entropy calculations\n",
    "- **Advantage**: Handles nominal variables well\n",
    "\n",
    "### 1.3 Ordinal Categorical Analysis\n",
    "\n",
    "#### Gamma (γ)\n",
    "- **For**: Two ordinal variables\n",
    "- **Formula**: `γ = (Concordant - Discordant) / (Concordant + Discordant)`\n",
    "- **Range**: -1 to +1\n",
    "- **Interpretation**: Direction and strength of monotonic association\n",
    "\n",
    "#### Kendall's Tau-b and Tau-c\n",
    "- **Tau-b**: For square tables\n",
    "- **Tau-c**: For rectangular tables\n",
    "- **Advantage**: Handles ties better than Gamma\n",
    "\n",
    "#### Somers' D\n",
    "- **Asymmetric**: Distinguishes dependent/independent variable\n",
    "- **Formula**: Based on concordant/discordant pairs\n",
    "- **Range**: -1 to +1\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Time Series Bivariate Analysis (Detailed Reference)\n",
    "\n",
    "### 2.1 Cross-Correlation Analysis\n",
    "**When applicable**: Two time series variables\n",
    "\n",
    "#### Cross-Correlation Function (CCF)\n",
    "- **Purpose**: Measure correlation at different lags\n",
    "- **Formula**: `CCF(k) = Σ[(X_t - μ_X)(Y_{t+k} - μ_Y)] / √(σ_X² × σ_Y²)`\n",
    "- **Output**: Correlation coefficients for lags k = ..., -2, -1, 0, 1, 2, ...\n",
    "- **Interpretation**:\n",
    "  - Positive lag: X leads Y\n",
    "  - Negative lag: Y leads X\n",
    "  - Zero lag: Contemporaneous correlation\n",
    "- **Python**: `statsmodels.tsa.stattools.ccf()`\n",
    "\n",
    "#### Lead-Lag Analysis\n",
    "- **Maximum CCF**: Identifies optimal lag relationship\n",
    "- **Applications**: Economic indicators, stock prices, sensor data\n",
    "- **Considerations**: Spurious correlations in trending data\n",
    "\n",
    "### 2.2 Cointegration Analysis\n",
    "\n",
    "#### Engle-Granger Test\n",
    "- **Purpose**: Test for long-run equilibrium relationship\n",
    "- **Steps**:\n",
    "  1. Test each series for unit root (ADF test)\n",
    "  2. Estimate cointegrating regression: `Y_t = α + βX_t + ε_t`\n",
    "  3. Test residuals for stationarity\n",
    "- **Python**: `statsmodels.tsa.stattools.coint()`\n",
    "\n",
    "#### Johansen Test\n",
    "- **Advantage**: Multiple cointegrating relationships\n",
    "- **Output**: Trace statistic, maximum eigenvalue statistic\n",
    "- **Applications**: Portfolio analysis, economic modeling\n",
    "\n",
    "### 2.3 Granger Causality\n",
    "\n",
    "#### Granger Causality Test\n",
    "- **Concept**: X Granger-causes Y if past values of X improve prediction of Y\n",
    "- **Method**: Compare restricted vs unrestricted VAR models\n",
    "- **Test Statistic**: F-test on lagged coefficients\n",
    "- **Python**: `statsmodels.tsa.stattools.grangercausalitytests()`\n",
    "- **Limitation**: Statistical causality ≠ true causality\n",
    "\n",
    "### 2.4 Vector Autoregression (VAR)\n",
    "\n",
    "#### VAR Model\n",
    "- **Structure**: Each variable regressed on lags of all variables\n",
    "- **Equation**: `Y_t = A₁Y_{t-1} + A₂Y_{t-2} + ... + A_pY_{t-p} + ε_t`\n",
    "- **Applications**: Forecasting, impulse response analysis\n",
    "- **Python**: `statsmodels.tsa.vector_ar.var_model.VAR()`\n",
    "\n",
    "#### Impulse Response Functions\n",
    "- **Purpose**: Trace effect of shock in one variable on others\n",
    "- **Output**: Response over time horizons\n",
    "- **Confidence Intervals**: Bootstrap or analytical methods\n",
    "\n",
    "### 2.5 Spectral Analysis\n",
    "\n",
    "#### Cross-Spectral Density\n",
    "- **Purpose**: Frequency domain relationship analysis\n",
    "- **Components**: Co-spectrum, quadrature spectrum\n",
    "- **Coherence**: Frequency-specific correlation\n",
    "- **Phase Spectrum**: Lead-lag relationships by frequency\n",
    "\n",
    "#### Wavelet Cross-Correlation\n",
    "- **Advantage**: Time-frequency analysis\n",
    "- **Applications**: Non-stationary relationships\n",
    "- **Output**: Correlation varying over time and frequency\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Advanced Multivariate Techniques (Detailed Reference)\n",
    "\n",
    "### 3.1 Information Theory Measures\n",
    "\n",
    "#### Mutual Information (MI)\n",
    "- **Formula**: `MI(X,Y) = ΣΣ p(x,y) log(p(x,y) / (p(x)p(y)))`\n",
    "- **Range**: 0 (independent) to ∞\n",
    "- **Advantage**: Captures non-linear relationships\n",
    "- **Python**: `sklearn.feature_selection.mutual_info_regression()`\n",
    "\n",
    "#### Normalized Mutual Information\n",
    "- **Formula**: `NMI = MI(X,Y) / √(H(X)H(Y))`\n",
    "- **Range**: 0 to 1\n",
    "- **Advantage**: Standardized for comparison\n",
    "\n",
    "#### Transfer Entropy\n",
    "- **Purpose**: Directional information transfer\n",
    "- **Formula**: Based on conditional mutual information\n",
    "- **Applications**: Causality detection in complex systems\n",
    "\n",
    "### 3.2 Distance-Based Methods\n",
    "\n",
    "#### Distance Correlation\n",
    "- **Advantage**: Detects all types of dependence\n",
    "- **Range**: 0 (independent) to 1 (dependent)\n",
    "- **Test**: Permutation-based significance testing\n",
    "- **Python**: `dcor` package\n",
    "\n",
    "#### Maximal Information Coefficient (MIC)\n",
    "- **Purpose**: Measure strength of relationship\n",
    "- **Range**: 0 to 1\n",
    "- **Advantage**: Equitability property\n",
    "- **Python**: `minepy` package\n",
    "\n",
    "### 3.3 Copula Analysis\n",
    "\n",
    "#### Copula Functions\n",
    "- **Purpose**: Model dependence structure separately from marginals\n",
    "- **Types**: Gaussian, t-copula, Archimedean copulas\n",
    "- **Applications**: Risk management, finance\n",
    "- **Python**: `copulas` package\n",
    "\n",
    "#### Kendall's Tau from Copula\n",
    "- **Relationship**: `τ = 4∫∫ C(u,v) dC(u,v) - 1`\n",
    "- **Advantage**: Distribution-free dependence measure\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Robust and Non-parametric Methods (Detailed Reference)\n",
    "\n",
    "### 4.1 Robust Correlation Methods\n",
    "\n",
    "#### Winsorized Correlation\n",
    "- **Method**: Replace extreme values with percentile values\n",
    "- **Typical**: 5th and 95th percentiles\n",
    "- **Advantage**: Reduces outlier influence\n",
    "\n",
    "#### Biweight Midcorrelation\n",
    "- **Advantage**: Robust to outliers, efficient\n",
    "- **Formula**: Uses biweight estimates of covariance and variance\n",
    "- **Python**: `astropy.stats.biweight_midcorrelation()`\n",
    "\n",
    "#### Percentage Bend Correlation\n",
    "- **Method**: Based on percentage bend estimators\n",
    "- **Parameter**: β (bending constant)\n",
    "- **Advantage**: Good breakdown point\n",
    "\n",
    "### 4.2 Rank-Based Methods\n",
    "\n",
    "#### Spearman's Rank Correlation (Detailed)\n",
    "- **Formula**: `ρ = 1 - (6Σd²) / (n(n²-1))`\n",
    "- **Tied Ranks**: Correction formula for ties\n",
    "- **Assumptions**: Monotonic relationship\n",
    "- **Significance Test**: t-test or exact distribution\n",
    "\n",
    "#### Kendall's Tau (Detailed)\n",
    "- **Tau-a**: `τ_a = (C - D) / (n(n-1)/2)`\n",
    "- **Tau-b**: Adjusts for ties in both variables\n",
    "- **Tau-c**: For rectangular tables\n",
    "- **Advantage**: Better for small samples\n",
    "\n",
    "### 4.3 Distribution-Free Tests\n",
    "\n",
    "#### Kolmogorov-Smirnov Two-Sample Test\n",
    "- **Purpose**: Compare two distributions\n",
    "- **Test Statistic**: `D = max|F₁(x) - F₂(x)|`\n",
    "- **Advantage**: Sensitive to any difference in distributions\n",
    "- **Python**: `scipy.stats.ks_2samp()`\n",
    "\n",
    "#### Anderson-Darling Two-Sample Test\n",
    "- **Advantage**: More sensitive to tail differences\n",
    "- **Test Statistic**: Weighted version of K-S test\n",
    "- **Python**: `scipy.stats.anderson_ksamp()`\n",
    "\n",
    "#### Energy Statistics\n",
    "- **E-statistic**: Distance-based test for equal distributions\n",
    "- **Advantage**: Consistent against all alternatives\n",
    "- **Applications**: High-dimensional data\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Specialized Domain Applications\n",
    "\n",
    "### 5.1 Survival Analysis Bivariate Methods\n",
    "\n",
    "#### Log-Rank Test\n",
    "- **Purpose**: Compare survival curves between groups\n",
    "- **Assumption**: Proportional hazards\n",
    "- **Python**: `lifelines.statistics.logrank_test()`\n",
    "\n",
    "#### Cox Proportional Hazards\n",
    "- **Bivariate**: Include interaction terms\n",
    "- **Hazard Ratio**: Measure of relative risk\n",
    "- **Python**: `lifelines.CoxPHFitter()`\n",
    "\n",
    "### 5.2 Spatial Analysis\n",
    "\n",
    "#### Spatial Autocorrelation\n",
    "- **Moran's I**: Global spatial autocorrelation\n",
    "- **Local Indicators**: LISA statistics\n",
    "- **Applications**: Geographic data analysis\n",
    "\n",
    "#### Cross-Variogram\n",
    "- **Purpose**: Spatial correlation between two variables\n",
    "- **Applications**: Geostatistics, environmental modeling\n",
    "\n",
    "### 5.3 Network Analysis\n",
    "\n",
    "#### Network Correlation\n",
    "- **Purpose**: Correlation in network-structured data\n",
    "- **Methods**: QAP correlation, network autocorrelation\n",
    "- **Applications**: Social networks, biological networks\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Power Analysis and Sample Size (Detailed Reference)\n",
    "\n",
    "### 6.1 Power Analysis Components\n",
    "\n",
    "#### Effect Size Measures\n",
    "- **Correlation**: r itself is the effect size\n",
    "- **Cohen's Guidelines**: 0.1 (small), 0.3 (medium), 0.5 (large)\n",
    "- **t-test**: Cohen's d = (μ₁ - μ₂) / σ_pooled\n",
    "- **ANOVA**: η² = SS_between / SS_total\n",
    "\n",
    "#### Power Calculation\n",
    "- **Formula**: Function of α, effect size, sample size\n",
    "- **Software**: G*Power, Python `statsmodels.stats.power`\n",
    "- **Types**: \n",
    "  - A priori: Determine required sample size\n",
    "  - Post hoc: Calculate achieved power\n",
    "  - Sensitivity: Determine detectable effect size\n",
    "\n",
    "### 6.2 Sample Size Determination\n",
    "\n",
    "#### Correlation Analysis\n",
    "- **Formula**: `n = (Z_α/2 + Z_β)² / (0.5 × ln((1+r)/(1-r)))² + 3`\n",
    "- **Fisher's Z-transformation**: Stabilizes variance\n",
    "- **Python**: `statsmodels.stats.power.ttest_power()`\n",
    "\n",
    "#### Two-Sample t-test\n",
    "- **Formula**: `n = 2σ²(Z_α/2 + Z_β)² / δ²`\n",
    "- **Equal vs Unequal**: Different formulas for equal/unequal group sizes\n",
    "- **Welch's t-test**: Adjustment for unequal variances\n",
    "\n",
    "#### Chi-Square Test\n",
    "- **Effect Size**: w = √(χ²/n)\n",
    "- **Sample Size**: Function of degrees of freedom and effect size\n",
    "- **Minimum Expected Frequency**: Rule of thumb ≥ 5\n",
    "\n",
    "### 6.3 Multiple Comparisons\n",
    "\n",
    "#### Bonferroni Correction\n",
    "- **Adjusted α**: α_adj = α / m (m = number of tests)\n",
    "- **Conservative**: Controls family-wise error rate\n",
    "- **Power Loss**: Reduced power with many comparisons\n",
    "\n",
    "#### False Discovery Rate (FDR)\n",
    "- **Benjamini-Hochberg**: Less conservative than Bonferroni\n",
    "- **Q-value**: FDR-adjusted p-value\n",
    "- **Python**: `statsmodels.stats.multitest.multipletests()`\n",
    "\n",
    "---\n",
    "\n",
    "*This reference guide provides detailed information for techniques not directly applicable to the current customer segmentation dataset but essential for comprehensive bivariate analysis across different data types and research contexts.*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
